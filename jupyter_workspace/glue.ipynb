{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea706121-591c-489a-995f-c6f7887f1202",
   "metadata": {},
   "source": [
    "# ETL Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223aff4-5de6-4aa4-8cbe-9c3634ba22f9",
   "metadata": {},
   "source": [
    "Start with the empty template glue job, run it to be sure everything is setup correctly.\n",
    "It should displat a SparkUI link as well, or go to [localhost:18080](http://localhost:18080) for the history server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd4805a-bcdd-4c91-8ae0-90661ccc3541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fd5dbe678052:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1-amzn-0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 17:10:16.2 [INFO] [logger:75] MainThread:sample_glue_job - Starting: sample_glue_job\n",
      "2022-12-05 17:10:16.3 [INFO] [logger:75] MainThread:sample_glue_job - Starting: setup\n",
      "2022-12-05 17:10:16.6 [INFO] [job:71] MainThread:sample_glue_job - Library Version: '0.1.0'\n",
      "2022-12-05 17:10:16.7 [INFO] [job:72] MainThread:sample_glue_job - Supplied Arguments: ['/home/glue_user/.local/lib/python3.7/site-packages/ipykernel_launcher.py', '-f', '/home/glue_user/.local/share/jupyter/runtime/kernel-01e9d1e9-aa6d-4dab-a5ad-4bbd35957a85.json', '--cfg_file_path', 'dummy', '--env_file_path', 'dummy']\n",
      "2022-12-05 17:10:16.8 [INFO] [job:73] MainThread:sample_glue_job - Parsed Arguments: {'job_bookmark_option': 'job-bookmark-disable', 'job_bookmark_from': None, 'job_bookmark_to': None, 'JOB_ID': None, 'JOB_RUN_ID': None, 'SECURITY_CONFIGURATION': None, 'encryption_type': None, 'enable_data_lineage': None, 'RedshiftTempDir': None, 'TempDir': None, 'env_file_path': 'dummy', 'cfg_file_path': 'dummy'}\n",
      "2022-12-05 17:10:16.50 [INFO] [job:74] MainThread:sample_glue_job - Spark Config: [('spark.eventLog.enabled', 'true'), ('spark.network.crypto.keyLength', '256'), ('spark.network.crypto.enabled', 'true'), ('spark.network.crypto.keyFactoryAlgorithm', 'PBKDF2WithHmacSHA256'), ('spark.driver.port', '45811'), ('spark.executor.extraClassPath', '/home/glue_user/spark/jars/*:/home/glue_user/aws-glue-libs/jars/*'), ('spark.executor.id', 'driver'), ('spark.authenticate.secret', '060b93c5-0bf9-494e-a604-766940b1a152'), ('spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs', 'false'), ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'), ('spark.unsafe.sorter.spill.read.ahead.enabled', 'false'), ('spark.app.name', 'pyspark-shell'), ('spark.app.startTime', '1670260213136'), ('spark.io.encryption.enabled', 'false'), ('spark.history.fs.logDirectory', 'file:////tmp/spark-events'), ('spark.app.id', 'local-1670260214167'), ('spark.sql.catalogImplementation', 'hive'), ('spark.driver.host', 'fd5dbe678052'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.network.crypto.saslFallback', 'false'), ('spark.submit.pyFiles', ''), ('spark.master', 'local[*]'), ('spark.submit.deployMode', 'client'), ('spark.driver.extraClassPath', '/home/glue_user/spark/jars/*:/home/glue_user/aws-glue-libs/jars/*'), ('spark.ui.showConsoleProgress', 'true'), ('spark.authenticate', 'true')]\n",
      "2022-12-05 17:10:16.512 [INFO] [job:97] MainThread:sample_glue_job - Skipping parsing config file: dummy\n",
      "2022-12-05 17:10:16.513 [INFO] [job:109] MainThread:sample_glue_job - Parsed Env: {}\n",
      "2022-12-05 17:10:16.514 [INFO] [job:97] MainThread:sample_glue_job - Skipping parsing config file: dummy\n",
      "2022-12-05 17:10:16.515 [INFO] [job:111] MainThread:sample_glue_job - Parsed Config: {}\n",
      "2022-12-05 17:10:16.516 [INFO] [logger:79] MainThread:sample_glue_job - End: setup [0.513s]\n",
      "2022-12-05 17:10:16.517 [INFO] [logger:75] MainThread:sample_glue_job - Starting: extract\n",
      "2022-12-05 17:10:16.518 [INFO] [logger:79] MainThread:sample_glue_job - End: extract [0.001s]\n",
      "2022-12-05 17:10:16.519 [INFO] [logger:75] MainThread:sample_glue_job - Starting: transform\n",
      "2022-12-05 17:10:16.520 [INFO] [logger:79] MainThread:sample_glue_job - End: transform [0.001s]\n",
      "2022-12-05 17:10:16.521 [INFO] [logger:75] MainThread:sample_glue_job - Starting: load\n",
      "2022-12-05 17:10:16.522 [INFO] [logger:79] MainThread:sample_glue_job - End: load [0.001s]\n",
      "2022-12-05 17:10:16.523 [INFO] [logger:75] MainThread:sample_glue_job - Starting: cleanup\n",
      "2022-12-05 17:10:16.532 [INFO] [logger:79] MainThread:sample_glue_job - End: cleanup [0.008s]\n",
      "2022-12-05 17:10:16.533 [INFO] [logger:79] MainThread:sample_glue_job - End: sample_glue_job [0.531s]\n"
     ]
    }
   ],
   "source": [
    "from pynutrien.aws.glue import GlueJob\n",
    "\n",
    "class SampleGlueJob(GlueJob):\n",
    "    job_name = \"sample_glue_job\"\n",
    "    arguments = []\n",
    "\n",
    "    def extract(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self):\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    import sys\n",
    "    # add your mandatory arguments\n",
    "    sys.argv.extend([\"--cfg_file_path\", \"dummy\", \"--env_file_path\", \"dummy\"])\n",
    "\n",
    "    job = SampleGlueJob()\n",
    "    display(job.spark_context)\n",
    "    job.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33756e77-eebe-4886-ab8e-317dedec4f9d",
   "metadata": {},
   "source": [
    "## Creating the job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1833c0-3284-405c-b071-f266dc86199f",
   "metadata": {},
   "source": [
    "Develop your workflow here using the `job` defined above. You can access the `job.spark_context`, `job.glue_context` or import other libraries. \n",
    "As you complete them, you can move them into the extract/transform/load methods to test the full job workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d492aa-cb77-4e23-bf6d-a0bd9384d4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
